{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Sentiment Analysis - Modeling\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries \n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV \n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier,GradientBoostingClassifier,RandomForestClassifier\n",
    "\n",
    "import joblib\n",
    "import xgboost as xgb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading https://files.pythonhosted.org/packages/c9/73/884e2d50ba8fc95bcb92c47910a8fbb8c80627f53a76250080c780c91185/xgboost-1.0.1-py3-none-win_amd64.whl (24.6MB)\n",
      "Requirement already satisfied: scipy in c:\\users\\leanne\\anaconda3\\lib\\site-packages (from xgboost) (1.4.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\leanne\\anaconda3\\lib\\site-packages (from xgboost) (1.17.4)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-1.0.1\n"
     ]
    }
   ],
   "source": [
    "# !pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling\n",
    "---\n",
    "\n",
    "In this segment, we will use the following models to classify the tweets. \n",
    "\n",
    "##### Models Used: \n",
    "1. Logistic Regression Model (??)\n",
    "2. Multinomial Naive Bayes Model \n",
    "3. Decision Tree\n",
    "3. Use of Grid Search to optimise the number of features in the count vectoriser in an attempt to improve model accuracy\n",
    "\n",
    "##### Metric to Validate Model: \n",
    "\n",
    "Accuracy is likely the best metric to use here as improperly classifying a subreddit post is equally bad in this instance.\n",
    "\n",
    "##### Outcome:\n",
    "\n",
    "The Multinomial Naive Bayes Model was able to accurately classify 91.8% of the posts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = '../datasets/tweets_clean_1.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pd.read_csv(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>airline_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>said</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>plu ad commerci experi tacki</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>today must mean need take anoth trip</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>realli aggress blast obnoxi entertain guest fa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>realli big bad thing</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  airline_sentiment\n",
       "0                                               said                  1\n",
       "1                       plu ad commerci experi tacki                  2\n",
       "2               today must mean need take anoth trip                  1\n",
       "3  realli aggress blast obnoxi entertain guest fa...                  0\n",
       "4                               realli big bad thing                  0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling \n",
    "\n",
    "General Approach\n",
    "- Split data into X and y \n",
    "- Train test split for model validation\n",
    "- Hyperparameter optimisation for count vectoriser, Tfidf transformer and model hyperparameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Split data into `X` and `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_1['text']\n",
    "y = df_1['airline_sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                 said\n",
       "1                         plu ad commerci experi tacki\n",
       "2                 today must mean need take anoth trip\n",
       "3    realli aggress blast obnoxi entertain guest fa...\n",
       "4                                 realli big bad thing\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline Accuracy \n",
    "Baseline accuracy for model is 62.7%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.627149\n",
       "1    0.211698\n",
       "2    0.161153\n",
       "Name: airline_sentiment, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Function for model validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(model_type, X,y):\n",
    "    \n",
    "    #train test split data for model validation\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    random_state=42,\n",
    "                                                    stratify = y)\n",
    "\n",
    "    #specifying models\n",
    "    models = {'lr': LogisticRegression(), \n",
    "              'nb': MultinomialNB(),\n",
    "              'dt': DecisionTreeClassifier(),\n",
    "              'rf': RandomForestClassifier(),\n",
    "              'ada': AdaBoostClassifier(base_estimator=DecisionTreeClassifier()),\n",
    "              'gb': GradientBoostingClassifier(),\n",
    "              'xgb': xgb.XGBClassifier(objective='multi:softmax',num_class=3) \n",
    "             }\n",
    "    \n",
    "    #creating a pipeline\n",
    "    pipe = Pipeline([\n",
    "        ('cvec', CountVectorizer()),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "        (model_type, models[model_type])\n",
    "    ])\n",
    "    \n",
    "    #pipeline parameters\n",
    "    pipe_params = {\n",
    "    'cvec__max_df': (.9, .8),\n",
    "    'cvec__max_features':[2500,3000,3500,5000],\n",
    "    'cvec__max_df':[0.9,0.95],\n",
    "    'cvec__ngram_range':[(1,1),(1,2)],\n",
    "    'tfidf__use_idf':[True,False],\n",
    "\n",
    "    }\n",
    "        \n",
    "    #additional parameters for each model \n",
    "    if model_type == 'nb':\n",
    "        pipe_params.update({'nb__alpha':[1,2]\n",
    "                           })\n",
    "        \n",
    "    elif model_type == 'lr':\n",
    "        pipe_params.update({'lr__penalty':['none','l2'],\n",
    "                            'lr__max_iter':[1000]\n",
    "                           })\n",
    "        \n",
    "    elif model_type == 'dt':\n",
    "        pipe_params.update({'dt__max_depth':[3,5,10],\n",
    "                           'dt__min_samples_split':[5,10,20],\n",
    "                           'dt__min_samples_leaf':[10,50,70]         #changed\n",
    "                           })\n",
    "    \n",
    "    elif model_type == 'rf':\n",
    "        pipe_params.update({'rf__n_estimators': [100,150,200],\n",
    "                            'rf__max_depth':[3,5,7]                  #changed\n",
    "                           })\n",
    "    elif model_type == 'ada':\n",
    "        pipe_params.update({'ada__n_estimators':[50,100],\n",
    "                            'ada__learning_rate':[0.9,1],             #changed param\n",
    "                            'ada__base_estimator__max_depth':[1,2,3]\n",
    "                           })\n",
    "    elif model_type == 'gb':\n",
    "        pipe_params.update({'gb__n_estimators': [50,100,150],\n",
    "                            'gb__learning_rate':[0.08, 0.1, 0.12],       #changed param\n",
    "                            'gb__max_depth':[1,2,3]\n",
    "        })\n",
    "        \n",
    "    elif model_type == 'xgb':\n",
    "        pipe_params.update({'xgb__max_depth':[1,2,3]\n",
    "        })\n",
    "\n",
    "\n",
    "    #grid search \n",
    "    gs = GridSearchCV(estimator = pipe, \n",
    "                        param_grid = pipe_params,\n",
    "                        verbose = 1,\n",
    "                        n_jobs = -1, \n",
    "                        cv = 5)\n",
    "    \n",
    "    print(\"Grid Search for \" + model_type)\n",
    "    print('===========================================================================')\n",
    "    \n",
    "    gs.fit(X_train,y_train)\n",
    "\n",
    "    print(f\"Best Score: {gs.best_score_}\")\n",
    "    print(f\"Best Parameters: {gs.best_params_}\")\n",
    "    \n",
    "    #train model on entire train data set using  best parameters\n",
    "    pipeline_final= Pipeline([\n",
    "    ('cvec', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    (model_type, models[model_type])\n",
    "    ])\n",
    "    \n",
    "    pipeline_final.set_params(**gs.best_params_)\n",
    "    final_model = pipeline_final.fit(X_train,y_train)\n",
    "    \n",
    "    print(\"Final Model Score\")\n",
    "    print()\n",
    "    print(f'Train Score:{final_model.score(X_train,y_train)}')\n",
    "    print(f'Test Score:{final_model.score(X_test,y_test)}')\n",
    "    \n",
    "    #save model with best parameters for use later\n",
    "    filename = 'model_' + model_type +'.pkl'\n",
    "    joblib.dump(final_model,filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid Search for lr\n",
      "===========================================================================\n",
      "Fitting 5 folds for each of 64 candidates, totalling 320 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   36.7s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  4.5min\n",
      "[Parallel(n_jobs=-1)]: Done 320 out of 320 | elapsed:  7.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.7782648401826484\n",
      "Best Parameters: {'cvec__max_df': 0.9, 'cvec__max_features': 5000, 'cvec__ngram_range': (1, 2), 'lr__max_iter': 1000, 'lr__penalty': 'l2', 'tfidf__use_idf': False}\n",
      "Final Model Score\n",
      "\n",
      "Train Score:0.8485844748858448\n",
      "Test Score:0.7814297452752671\n"
     ]
    }
   ],
   "source": [
    "run_model('lr',X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid Search for nb\n",
      "===========================================================================\n",
      "Fitting 5 folds for each of 64 candidates, totalling 320 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   18.0s\n",
      "[Parallel(n_jobs=-1)]: Done 320 out of 320 | elapsed:   31.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.7365296803652968\n",
      "Best Parameters: {'cvec__max_df': 0.9, 'cvec__max_features': 2500, 'cvec__ngram_range': (1, 2), 'nb__alpha': 1, 'tfidf__use_idf': False}\n",
      "Final Model Score\n",
      "\n",
      "Train Score:0.7754337899543379\n",
      "Test Score:0.7376061353053958\n"
     ]
    }
   ],
   "source": [
    "run_model('nb',X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid Search for dt\n",
      "===========================================================================\n",
      "Fitting 5 folds for each of 864 candidates, totalling 4320 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   11.9s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:   41.2s\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1234 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1784 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=-1)]: Done 2434 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=-1)]: Done 3184 tasks      | elapsed:  5.7min\n",
      "[Parallel(n_jobs=-1)]: Done 4034 tasks      | elapsed:  7.1min\n",
      "[Parallel(n_jobs=-1)]: Done 4320 out of 4320 | elapsed:  7.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.6889497716894978\n",
      "Best Parameters: {'cvec__max_df': 0.9, 'cvec__max_features': 5000, 'cvec__ngram_range': (1, 2), 'dt__max_depth': 10, 'dt__min_samples_leaf': 10, 'dt__min_samples_split': 5, 'tfidf__use_idf': False}\n",
      "Final Model Score\n",
      "\n",
      "Train Score:0.6962557077625571\n",
      "Test Score:0.6926869350862778\n"
     ]
    }
   ],
   "source": [
    "run_model('dt',X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid Search for rf\n",
      "===========================================================================\n",
      "Fitting 5 folds for each of 288 candidates, totalling 1440 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    7.0s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   47.8s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1234 tasks      | elapsed:  5.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1440 out of 1440 | elapsed:  6.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.628310502283105\n",
      "Best Parameters: {'cvec__max_df': 0.9, 'cvec__max_features': 2500, 'cvec__ngram_range': (1, 2), 'rf__max_depth': 7, 'rf__n_estimators': 100, 'tfidf__use_idf': True}\n",
      "Final Model Score\n",
      "\n",
      "Train Score:0.628675799086758\n",
      "Test Score:0.6280471103807176\n"
     ]
    }
   ],
   "source": [
    "run_model('rf',X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ada Boost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid Search for ada\n",
      "===========================================================================\n",
      "Fitting 5 folds for each of 384 candidates, totalling 1920 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   10.3s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:  5.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1234 tasks      | elapsed:  9.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1784 tasks      | elapsed: 15.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1920 out of 1920 | elapsed: 17.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.7252968036529681\n",
      "Best Parameters: {'ada__base_estimator__max_depth': 2, 'ada__learning_rate': 1, 'ada__n_estimators': 100, 'cvec__max_df': 0.95, 'cvec__max_features': 5000, 'cvec__ngram_range': (1, 1), 'tfidf__use_idf': False}\n",
      "Final Model Score\n",
      "\n",
      "Train Score:0.7754337899543379\n",
      "Test Score:0.7252807450013695\n"
     ]
    }
   ],
   "source": [
    "run_model('ada',X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid Search for gb\n",
      "===========================================================================\n",
      "Fitting 5 folds for each of 864 candidates, totalling 4320 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   29.5s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:  9.9min\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed: 18.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1234 tasks      | elapsed: 29.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1784 tasks      | elapsed: 43.2min\n",
      "[Parallel(n_jobs=-1)]: Done 2434 tasks      | elapsed: 59.9min\n",
      "[Parallel(n_jobs=-1)]: Done 3184 tasks      | elapsed: 78.0min\n",
      "[Parallel(n_jobs=-1)]: Done 4034 tasks      | elapsed: 99.5min\n",
      "[Parallel(n_jobs=-1)]: Done 4320 out of 4320 | elapsed: 108.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.7421004566210045\n",
      "Best Parameters: {'cvec__max_df': 0.9, 'cvec__max_features': 5000, 'cvec__ngram_range': (1, 2), 'gb__learning_rate': 0.12, 'gb__max_depth': 3, 'gb__n_estimators': 150, 'tfidf__use_idf': False}\n",
      "Final Model Score\n",
      "\n",
      "Train Score:0.7842922374429224\n",
      "Test Score:0.7299370035606683\n"
     ]
    }
   ],
   "source": [
    "run_model('gb',X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid Search for xgb\n",
      "===========================================================================\n",
      "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   54.3s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  4.6min\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed: 11.0min\n",
      "[Parallel(n_jobs=-1)]: Done 480 out of 480 | elapsed: 12.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.7435616438356165\n",
      "Best Parameters: {'cvec__max_df': 0.9, 'cvec__max_features': 2500, 'cvec__ngram_range': (1, 1), 'tfidf__use_idf': False, 'xgb__max_depth': 3}\n",
      "Final Model Score\n",
      "\n",
      "Train Score:0.7750684931506849\n",
      "Test Score:0.7359627499315257\n"
     ]
    }
   ],
   "source": [
    "run_model('xgb',X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Model                    | Accuracy Score |\n",
    "|--------------------------|----------------|\n",
    "| Logistic Regression      | 0\\.781         |\n",
    "| Naive Bayes              | 0\\.737         |\n",
    "| Decision Tree            | 0\\.692         |\n",
    "| Random Forest Classifier | 0\\.634         |\n",
    "| Ada Boost                | 0\\.726         |\n",
    "| Gradient Boost           | 0\\.717         |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loaded_model = joblib.load(filename)\n",
    "# result = loaded_model.score(X_test, Y_test)\n",
    "# print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
